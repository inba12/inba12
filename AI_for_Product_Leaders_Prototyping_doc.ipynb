{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/inbarasuvs/inba12/blob/main/AI_for_Product_Leaders_Prototyping_doc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Install all the requirements and supress pip installation\n",
        "!pip install -q loguru openai gradio >/dev/null 2>&1"
      ],
      "metadata": {
        "id": "PaE9OZlBqxqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "78sm5as5OuV_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Core imports for OpenAI API interaction and UI\n",
        "import openai\n",
        "import os\n",
        "from loguru import logger #For logging\n",
        "from google.colab import userdata #for handing API Keys\n",
        "import gradio as gr #for UI"
      ],
      "metadata": {
        "id": "9sgsmYATrWSj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K-U9yS-Xokxj",
        "outputId": "8c9776f9-8d45-4241-d260-395e4f36f8d7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2024-11-22 13:21:21.764\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36m<cell line: 3>\u001b[0m:\u001b[36m3\u001b[0m - \u001b[1mOpenAI API key: LOADED ✓\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "#Fetch and ensure OpenAI API Keys are there\n",
        "api_key = userdata.get('OPENAI_API_KEY')\n",
        "logger.info(f\"OpenAI API key: {'LOADED ✓' if api_key.startswith('sk-') else 'NOT FOUND ✗'}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define OpenAI client\n",
        "client = openai.OpenAI(api_key=api_key)"
      ],
      "metadata": {
        "id": "7Iz1MP-mqQcv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_completion(prompt, model=\"gpt-4o-mini\"):\n",
        "    \"\"\"\n",
        "    Get completion from OpenAI API.\n",
        "\n",
        "    Args:\n",
        "        prompt (str): Input text to send to OpenAI\n",
        "        model (str): OpenAI model to use, defaults to GPT-4\n",
        "\n",
        "    Returns:\n",
        "        str: Generated completion text\n",
        "    \"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0.2\n",
        "    )\n",
        "    final_response = response.choices[0].message.content\n",
        "    logger.info(f\"Mode response: {final_response}\")\n",
        "\n",
        "    return final_response"
      ],
      "metadata": {
        "id": "dL6VzpimsRGM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_prompt(your_role, candidate_role, your_review):\n",
        "    delimiter = \"####\"\n",
        "\n",
        "    prompt = f\"\"\"\n",
        "    I’m {your_role}. You’re an expert at writing performance reviews. On my behalf, help answer the question for performance reviews below.\n",
        "\n",
        "    {delimiter} Instructions {delimiter}:\n",
        "    - Use the context below to understand my perspective of working with him\n",
        "    - Keep the role of person I’m review {candidate_role} in mind when writing the review\n",
        "    - Use simple language and keep it to the point\n",
        "    - Strictly answer the question mentioned in “question for performance”\n",
        "\n",
        "    {your_review}\n",
        "\n",
        "    - Describe example(s) of the topics selected. What was the context? What actions did they take?\n",
        "    - In your opinion, what impact did their actions have?\n",
        "    - What recommendations do you have for their growth and development? Your feedback can be about any area of their work.\n",
        "\n",
        "\n",
        "    {delimiter} Output in markdown format in following structure:{delimiter}\n",
        "    - Q1: Describe example(s) of the topics selected. What was the context? What actions did they take?\n",
        "    Your answer\n",
        "    - Q2: In your opinion, what impact did their actions have?\n",
        "    Your answer\n",
        "    - Q3: What recommendations do you have for their growth and development? Your feedback can be about any area of their work.\n",
        "    Your answer\n",
        "\n",
        "    Answer: \"\"\"\n",
        "    return prompt"
      ],
      "metadata": {
        "id": "3eaMigKJsV1z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_review(your_role, candidate_role, your_review):\n",
        "    \"\"\"\n",
        "    Generate a structured performance review using OpenAI.\n",
        "\n",
        "    Args:\n",
        "        your_role (str): Reviewer's role\n",
        "        candidate_role (str): Candidate's role\n",
        "        your_review (str): Initial review text\n",
        "\n",
        "    Returns:\n",
        "        str: Formatted performance review\n",
        "    \"\"\"\n",
        "    prompt = generate_prompt(your_role, candidate_role, your_review)\n",
        "    response = get_completion(prompt)\n",
        "    return response"
      ],
      "metadata": {
        "id": "D8O3uv0mCV5W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a Gradio interface using Blocks for more flexible layout\n",
        "with gr.Blocks() as demo:\n",
        "    # Add header with decorative separators\n",
        "    gr.Markdown(\"============================================================\")\n",
        "    gr.Markdown(\"Write performance review in a minute\")  # Title\n",
        "    gr.Markdown(\"============================================================\")\n",
        "\n",
        "    # Input Fields\n",
        "    your_role = gr.Textbox(\n",
        "        label='your role',  # e.g., \"Senior Manager\", \"Team Lead\"\n",
        "    )\n",
        "\n",
        "    candidate_role = gr.Textbox(\n",
        "        label='candidate role',  # e.g., \"Software Engineer\", \"Product Manager\"\n",
        "    )\n",
        "\n",
        "    your_review = gr.Textbox(\n",
        "        label='Briefly descrive your experience of working with candididate...',\n",
        "        # This is the main input where reviewer provides detailed feedback\n",
        "        # Can include:\n",
        "        # - Project details\n",
        "        # - Responsibilities\n",
        "        # - Achievements\n",
        "        # - Behavioral observations\n",
        "    )\n",
        "\n",
        "    # Action button to trigger review generation\n",
        "    write_review = gr.Button(\"Write Review\")\n",
        "\n",
        "    # Output area where the AI-generated review will appear\n",
        "    answer = gr.Markdown(\n",
        "        label='Review'  # Will display formatted review in markdown\n",
        "    )\n",
        "\n",
        "    # Connect the interface:\n",
        "    # When button is clicked:\n",
        "    # 1. Take inputs from all three textboxes\n",
        "    # 2. Pass them to generate_review function\n",
        "    # 3. Display result in answer markdown\n",
        "    write_review.click(\n",
        "        fn=generate_review,            # Function to call\n",
        "        inputs=[                       # List of inputs to pass to function\n",
        "            your_role,\n",
        "            candidate_role,\n",
        "            your_review\n",
        "        ],\n",
        "        outputs=answer                 # Where to display the result\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(\n",
        "    share=True,     # Create a public link\n",
        "    debug=True      # Show debugging information\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "xmmkg44Wuwex",
        "outputId": "b172a198-370d-4a80-c000-edf9b8b6b9f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://6b6bee9fc9af3e0d8d.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://6b6bee9fc9af3e0d8d.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m2024-11-22 13:25:28.746\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_completion\u001b[0m:\u001b[36m19\u001b[0m - \u001b[1mMode response: - Q1: Describe example(s) of the topics selected. What was the context? What actions did they take?  \n",
            "Mohak played a crucial role in the batch operations project for the Cloud Storage team. He assisted in writing the Product Requirements Document (PRD) and participated in design discussions, ensuring that all aspects of the project were well thought out. Additionally, he was actively involved in customer meetings, where he addressed customer questions and concerns. His contributions were vital in keeping the project on track and aligned with customer needs.\n",
            "\n",
            "- Q2: In your opinion, what impact did their actions have?  \n",
            "Mohak's actions had a significant positive impact on the project. His involvement in the PRD and design discussions helped clarify project goals and requirements, leading to a smoother development process. By engaging with customers directly, he ensured that their feedback was incorporated, which ultimately contributed to the successful and timely launch of the product. His proactive approach fostered collaboration within the team and built trust with customers.\n",
            "\n",
            "- Q3: What recommendations do you have for their growth and development? Your feedback can be about any area of their work.  \n",
            "To further enhance his skills, I recommend that Mohak focus on deepening his technical expertise in software development, particularly in areas related to cloud technologies. Additionally, he could benefit from taking on more leadership roles in future projects, which would help him develop his project management and mentoring abilities. Participating in training or workshops on advanced software design principles could also be beneficial for his growth.\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://6b6bee9fc9af3e0d8d.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Sample Review to test:\n",
        "\n",
        ">I worked with Mohak on multiple projects. One of the projects was batch operations, which was a priority of Cloud Storage team, where he helped me write the PRD, do the design discussion. He was present in customer meetings and helped answer customer questions. Overall, this helped launch the product on time.\n",
        "\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "W6Uyxhj8voSb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "b8d39e37-e53e-4725-9e8a-e338684a1e5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nSample Review to test:\\n\\n>I worked with Mohak on multiple projects. One of the projects was batch operations, which was a priority of Cloud Storage team, where he helped me write the PRD, do the design discussion. He was present in customer meetings and helped answer customer questions. Overall, this helped launch the product on time.\\n\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    }
  ]
}